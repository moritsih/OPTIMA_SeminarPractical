{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm\n",
    "import SimpleITK as sitk\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from monai.networks.nets import BasicUNetPlusPlus\n",
    "from monai.transforms import *\n",
    "\n",
    "import wandb\n",
    "\n",
    "\n",
    "'''\n",
    "1. RETOUCH dataset\n",
    "\n",
    "    Preprocessing\n",
    "    - Preprocessed dataset for now\n",
    "\n",
    "    Training/validation/test\n",
    "    - split train folder into 75/15/10\n",
    "    - Use Topcon&Cirrus for validation and testing too? Or use ONLY Topcon&Cirrus for val&test?\n",
    "        > Paper uses only topcon and cirrus for validation and testing\n",
    "\n",
    "    SVDNA\n",
    "    - Create Pytorch Dataset class:\n",
    "        > define __getitem__ method such that I give it the path to the training set and it returns the SVDNA transformed images\n",
    "\n",
    "    - when epoch starts, SVDNA is applied to each image\n",
    "        > for each image, 1/3 chance to choose one of the domains\n",
    "            > of the n_d images, one is chosen randomly for style transfer\n",
    "        > for each image, k is sampled between 30 and 50\n",
    "        > apply SVDNA using sampled image and k\n",
    "    - Implementation:\n",
    "        > dict containing spectralis images\n",
    "        > dict containing cirrus and topcon images\n",
    "\n",
    "        for epoch in total_epochs:\n",
    "            source_imgs = spectralis_img\n",
    "            target_imgs = cirrus_topcon_img\n",
    "\n",
    "            source_svdna = [svdna(imgs[i], target_imgs):labels[i] for imgs, labels in source_imgs.items()]\n",
    "\n",
    "            img_dataloader = Dataloader(source_svdna)\n",
    "\n",
    "    Transformations\n",
    "    - \n",
    "\n",
    "\n",
    "    - Possibilities for datastructure:\n",
    "        - [{cirrus_img1:cirrus_img1, cirrus_img1_label:cirrus_img1_label}, {cirrus_img2:cirrus_img2, cirrus_img2_label:cirrus_img2_label}, ...]\n",
    "\n",
    "    \n",
    "        \n",
    "https://docs.monai.io/en/stable/networks.html#basicunetplusplus\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "\n",
    "data_dir = Path.cwd() / 'data' / 'Retouch-preprocessed'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 1024, 512)\n"
     ]
    }
   ],
   "source": [
    "sample_img = '/Users/moritz/Documents/Master/OPTIMA_Masterarbeit/practical/data/RETOUCH/TrainingSet-Release/Cirrus/03a60d9078d35b1488e6030880a29014/reference.mhd'\n",
    "itk_image = sitk.ReadImage(sample_img)\n",
    "image_array = sitk.GetArrayViewFromImage(itk_image)\n",
    "\n",
    "# print the image's dimensions\n",
    "print(image_array.shape)\n",
    "\n",
    "# plot the image\n",
    "for i in range(128):\n",
    "    if i % 10 == 0:\n",
    "        pass\n",
    "        #plt.imshow(image_array[i], cmap='gray')\n",
    "        #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_dir = Path(Path.cwd() / 'data/RETOUCH/TrainingSet-Release/')\n",
    "train_dir = Path(Path.cwd() / 'data/Retouch-Preprocessed/train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  Topcon ; Number of folders:  22\n",
      "Device:  Spectralis ; Number of folders:  24\n",
      "Device:  Cirrus ; Number of folders:  24\n",
      "Preprocessed Retouch folders:  70\n"
     ]
    }
   ],
   "source": [
    "data = {}\n",
    "for device in os.listdir(name_dir):\n",
    "    data[device] = os.listdir(name_dir / device)\n",
    "\n",
    "for device, vals in data.items():\n",
    "    print(\"Device: \", device, \"; Number of folders: \", len(vals))\n",
    "\n",
    "print(\"Preprocessed Retouch folders: \", len(os.listdir(train_dir)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_black_images(main_folder, delete_images=False):\n",
    "    \"\"\"\n",
    "    Generate black images for missing files in the label_image folder.\n",
    "\n",
    "    Args:\n",
    "        main_folder (str or Path): Path to the main folder.\n",
    "        delete_images (bool, optional): Flag to delete the generated black images. Defaults to False.\n",
    "    \"\"\"\n",
    "\n",
    "    if not delete_images:\n",
    "    # Iterate over the subfolders\n",
    "        for subfolder in sorted(os.listdir(main_folder)):\n",
    "            subfolder_path = main_folder / subfolder\n",
    "\n",
    "            # Check if the subfolder contains the 'image' and 'label_image' folders\n",
    "            if os.path.isdir(subfolder_path) and 'image' in os.listdir(subfolder_path) and 'label_image' in os.listdir(subfolder_path):\n",
    "                image_folder = subfolder_path / 'image'\n",
    "                label_folder = subfolder_path / 'label_image'\n",
    "\n",
    "                # Get the set of filenames in the 'image' folder\n",
    "                image_files = sorted(set(os.listdir(image_folder)))\n",
    "\n",
    "                # Get the set of filenames in the 'label_image' folder\n",
    "                label_files = sorted(set(os.listdir(label_folder)))\n",
    "\n",
    "                # Find the filenames that are in 'label_image' but not in 'image'\n",
    "                missing_files = [i for i in image_files if i not in label_files]\n",
    "\n",
    "                # Create a black image for each missing file\n",
    "                for file in missing_files:\n",
    "                    file_path = label_folder / file\n",
    "\n",
    "                    # find the shape of the input image to create corresponding target\n",
    "                    file_shape = cv2.imread(str(image_folder / file)).shape\n",
    "                    black_image = np.zeros(file_shape)\n",
    "\n",
    "                    # make unique names so files can be deleted again\n",
    "                    cv2.imwrite(f\"{str(file_path)[:-4]}_empty.png\", black_image)\n",
    "\n",
    "    # Delete the generated black images if delete_images flag is True\n",
    "    if delete_images:\n",
    "        for subfolder in sorted(os.listdir(main_folder)):\n",
    "            subfolder_path = main_folder / subfolder\n",
    "            if os.path.isdir(subfolder_path) and 'label_image' in os.listdir(subfolder_path):\n",
    "                label_folder = subfolder_path / 'label_image'\n",
    "                for file in os.listdir(label_folder):\n",
    "                    file_path = label_folder / file\n",
    "                    if \"_empty\" in str(file):\n",
    "                        os.remove(str(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate_black_images(train_dir, delete_images=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Below class should just be a function that does the following:\n",
    "sort data and output one large list of dicts for all source images and one for all target images. Transforms are applied in the monai or torch\n",
    "dataset classes. they don't need to be created.\n",
    "'''\n",
    "\n",
    "\n",
    "class OCTDataset(Dataset):\n",
    "    '''\n",
    "    Custon dataset object accomplishes the task of bringing the training data into the right format for further processing.\n",
    "    '''\n",
    "    \n",
    "    def __init__(self, data_path: str, transform=None, generate_empty_labels=False, source_domain='Spectralis'):\n",
    "\n",
    "        self.data_path = Path(data_path)\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "        if generate_empty_labels:\n",
    "            self.generate_black_images(data_path) # check if this misses arguments\n",
    "                                                  # change method so it only creates black images for source domain\n",
    "\n",
    "        self.dict_domain_images_sorted = self.filter_source_domain(data_path, source_domain)\n",
    "\n",
    "        self.source_domain_dict = self.dict_domain_images_sorted[source_domain]\n",
    "        self.target_domain_dict = [img_dict for domain in self.dict_domain_images_sorted if domain != source_domain for img_dict in self.dict_domain_images_sorted[domain]]\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.source_data_paths)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        source_img = self.source_domain_dict[index]\n",
    "        target_img = self.target_domain_dict[index]\n",
    "        \n",
    "        if self.transform:\n",
    "            # Apply transformations dynamically during training\n",
    "            pass\n",
    "            #source_img, target_img = self.transform(source_img, target_img)\n",
    "\n",
    "        return source_img, target_img\n",
    "\n",
    "\n",
    "    def filter_source_domain(self, data_path, source_domain):\n",
    "        '''\n",
    "        data_path: Path to the training set folder where all images are not sorted by domains.\n",
    "        source_domain: The source domain for the upcoming SVDNA process.\n",
    "\n",
    "        Returns: a dictionary containing three lists of dictionaries of the following structure:\n",
    "                    {source domain: [{img: img1, label: label1}, {img: img2, label: label2}, ...], \n",
    "                    target domain 1: [{img: img1}, {img: img2}, ...],\n",
    "                    target domain 2: [{img: img1}, {img: img2}, ...]}\n",
    "        '''\n",
    "        \n",
    "        named_domain_folder = Path.cwd() / 'data/RETOUCH/TrainingSet-Release'\n",
    "\n",
    "        domains = os.listdir(named_domain_folder)\n",
    "\n",
    "        # creates dict e.g. {'cirrus':['path1', 'path2', ...], 'topcon':['path1', 'path2', ...]}\n",
    "        img_folders_sorted_by_domain = {domain:os.listdir(named_domain_folder / domain) for domain in domains}\n",
    "\n",
    "\n",
    "        # restructure source data into a list of dictionaries, where each dictionary has keys img and label\n",
    "\n",
    "        unsorted_img_folders_training_set = os.listdir(data_path)\n",
    "\n",
    "        domains_dict = {}\n",
    "\n",
    "        for domain in domains:\n",
    "            \n",
    "            list_of_dicts_images = []\n",
    "            \n",
    "            for img_folder in unsorted_img_folders_training_set:\n",
    "\n",
    "                if img_folder in img_folders_sorted_by_domain[domain]:\n",
    "                    \n",
    "                    subfolders = os.listdir(data_path / img_folder)\n",
    "                    unsorted_img_folders_training_set.remove(img_folder)\n",
    "\n",
    "                    if 'image' in subfolders and 'label_image' in subfolders:\n",
    "                        \n",
    "                        if domain == source_domain:\n",
    "            \n",
    "                            sliced_images = sorted(os.listdir(data_path / img_folder / 'image'))\n",
    "                            sliced_labels = sorted(os.listdir(data_path / img_folder / 'label_image'))\n",
    "                            \n",
    "                            for i in range(len(sliced_images)):\n",
    "                                if (sliced_images[i] == sliced_labels[i]) or (sliced_images[i][:-4] + '_empty.png' == sliced_labels[i]):\n",
    "                                    list_of_dicts_images.append(\n",
    "                                        {'img': str(data_path / img_folder / 'image' / sliced_images[i]), 'label': str(data_path / img_folder / 'label_image' / sliced_labels[i])}\n",
    "                                        )\n",
    "\n",
    "                                else:\n",
    "                                    print(f\"Image {img_folder}/image/{sliced_images[i]} has no corresponding label image. Skipping image. \\nTake a look at 'generate_black_images' method.\") \n",
    "                                    continue\n",
    "                        \n",
    "                        else:\n",
    "\n",
    "                            sliced_images = sorted(os.listdir(data_path / img_folder / 'image'))\n",
    "\n",
    "                            for i in range(len(sliced_images)):\n",
    "                                    list_of_dicts_images.append({'img': str(data_path / img_folder / 'image' / sliced_images[i])})\n",
    "                        \n",
    "            domains_dict[domain] = list_of_dicts_images\n",
    "                                        \n",
    "        return domains_dict\n",
    "\n",
    "    def generate_black_images(self, main_folder, delete_images=False):\n",
    "        \"\"\"\n",
    "        Generate black images for missing files in the label_image folder.\n",
    "\n",
    "        Args:\n",
    "            main_folder (str or Path): Path to the main folder.\n",
    "            delete_images (bool, optional): Flag to delete the generated black images. Defaults to False.\n",
    "        \"\"\"\n",
    "\n",
    "        if not delete_images:\n",
    "        # Iterate over the subfolders\n",
    "            for subfolder in sorted(os.listdir(main_folder)):\n",
    "                subfolder_path = main_folder / subfolder\n",
    "\n",
    "                # Check if the subfolder contains the 'image' and 'label_image' folders\n",
    "                if os.path.isdir(subfolder_path) and 'image' in os.listdir(subfolder_path) and 'label_image' in os.listdir(subfolder_path):\n",
    "                    image_folder = subfolder_path / 'image'\n",
    "                    label_folder = subfolder_path / 'label_image'\n",
    "\n",
    "                    # Get the set of filenames in the 'image' folder\n",
    "                    image_files = sorted(set(os.listdir(image_folder)))\n",
    "\n",
    "                    # Get the set of filenames in the 'label_image' folder\n",
    "                    label_files = sorted(set(os.listdir(label_folder)))\n",
    "\n",
    "                    # Find the filenames that are in 'label_image' but not in 'image'\n",
    "                    missing_files = [i for i in image_files if i not in label_files]\n",
    "\n",
    "                    # Create a black image for each missing file\n",
    "                    for file in missing_files:\n",
    "                        file_path = label_folder / file\n",
    "\n",
    "                        # find the shape of the input image to create corresponding target\n",
    "                        file_shape = cv2.imread(str(image_folder / file)).shape\n",
    "                        black_image = np.zeros(file_shape)\n",
    "\n",
    "                        # make unique names so files can be deleted again\n",
    "                        cv2.imwrite(f\"{str(file_path)[:-4]}_empty.png\", black_image)\n",
    "\n",
    "        # Delete the generated black images if delete_images flag is True\n",
    "        if delete_images:\n",
    "            for subfolder in sorted(os.listdir(main_folder)):\n",
    "                subfolder_path = main_folder / subfolder\n",
    "                if os.path.isdir(subfolder_path) and 'label_image' in os.listdir(subfolder_path):\n",
    "                    label_folder = subfolder_path / 'label_image'\n",
    "                    for file in os.listdir(label_folder):\n",
    "                        file_path = label_folder / file\n",
    "                        if \"_empty\" in str(file):\n",
    "                            os.remove(str(file_path))\n",
    "\n",
    "    def delete_generated_labels(self):\n",
    "        # Delete the generated black images\n",
    "        self.generate_black_images(delete_images=True)\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Define the randomizable transformation class for dynamic transformations\n",
    "class RandomTransform(RandomizableTransform):\n",
    "    def __call__(self, source_img, target_img):\n",
    "        self.randomize()\n",
    "        # Implement your dynamic random transformations\n",
    "        # Apply random transformations to both source and target images\n",
    "        #return transformed_source_img, transformed_target_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define the UNet model\n",
    "class SegmentationUNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SegmentationUNet, self).__init__()\n",
    "        # Define your UNet architecture using MONAI\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Implement your forward pass logic\n",
    "        return x\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_ready = False\n",
    "\n",
    "if training_ready:\n",
    "\n",
    "    # Initialize wandb\n",
    "    wandb.init(project=\"PracticalWorkinAI\", name=\"svdna_reproduction_retouch_only\")\n",
    "\n",
    "    # Instantiate the model, loss function, and optimizer\n",
    "    model = SegmentationUNet()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    # Define the dataset paths\n",
    "    source_data_paths = [...]  # List of paths to source domain data\n",
    "    target_data_paths = [...]  # List of paths to target domain data\n",
    "\n",
    "    # Create the dataset and dataloader\n",
    "    transform = Compose([\n",
    "        RandomTransform(),\n",
    "        svdna,  # Apply SVDNA function\n",
    "        ToTensord()\n",
    "    ])\n",
    "\n",
    "    dataset = OCTDataset(source_data_paths, target_data_paths, transform=transform)\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "    # Training loop\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch_idx, (source_img, target_img) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(source_img)\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, target_img)\n",
    "\n",
    "            # Backward pass and optimization\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Log loss to wandb\n",
    "            wandb.log({\"Loss\": loss.item(), \"Epoch\": epoch, \"Batch\": batch_idx})\n",
    "\n",
    "            # Print progress\n",
    "            print(f'Epoch [{epoch+1}/{num_epochs}], Batch [{batch_idx+1}/{len(dataloader)}], Loss: {loss.item()}')\n",
    "\n",
    "    # Save the trained model if needed\n",
    "    torch.save(model.state_dict(), 'segmentation_unet.pth')\n",
    "\n",
    "    # Finish wandb run\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from typing import Hashable, Optional, Union, Sequence\n",
    "import scipy.ndimage\n",
    "\n",
    "from typing import *\n",
    "from monai.transforms import *\n",
    "from monai.config.type_definitions import KeysCollection\n",
    "\n",
    "labels_mapping = {255: 0,\n",
    "                  0: 1,\n",
    "                  80: 2,\n",
    "                  160: 3}\n",
    "\n",
    "class LayerPositionToProbabilityMap(MapTransform):\n",
    "    def __init__(self, keys: Sequence, target_size,target_keys: Sequence = None):\n",
    "        super().__init__(keys)\n",
    "        if target_keys is None:\n",
    "            self.target_keys = keys\n",
    "        self.target_keys = target_keys\n",
    "        self.target_size = target_size\n",
    "    \n",
    "    def smoothing_function(self, mask):\n",
    "        mean = 0\n",
    "        std = 0.5\n",
    "        scale = 1 / (std * np.sqrt(2 * np.pi))\n",
    "        return scale * np.exp(-(mask - mean)**2 / (2 * std**2))\n",
    "        #return -(mask - mean)**2 / (2 * std**2)\n",
    "        \n",
    "    def __call__(self, data):\n",
    "        for i, key in enumerate(self.keys):\n",
    "            layer = data[key]\n",
    "            column = np.arange(self.target_size[1])\n",
    "            column = np.expand_dims(column, 1)\n",
    "            mask = np.repeat(column, self.target_size[0], axis=1)\n",
    "            mask = np.expand_dims(mask, 0)\n",
    "            mask = np.repeat(mask, layer.shape[0], axis=0)\n",
    "            #layer = np.expand_dims(layer, 1)\n",
    "            mask = mask - layer\n",
    "            #mask = np.ones_like(mask)\n",
    "            mask = mask.astype(np.float32)\n",
    "            \n",
    "            mask = self.smoothing_function(mask)\n",
    "            mask = mask / np.expand_dims(mask.sum(axis=1), axis=2)\n",
    "            data[self.target_keys[i]] = mask\n",
    "\n",
    "            \n",
    "        return data\n",
    "    \n",
    "\n",
    "class CropImages(MapTransform):\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, source_key : str, crop_size, crop_allowance=10, allow_missing_keys: bool = False) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.source_key = source_key\n",
    "        self.crop_size = crop_size\n",
    "        self.crop_allowance = crop_allowance\n",
    "\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "\n",
    "        d = dict(data)\n",
    "        for ki, key in enumerate(self.keys):\n",
    "            preliminary = data[self.source_key]\n",
    "            min_val = max(preliminary.min() - self.crop_allowance, 0)\n",
    "            img = data[key]\n",
    "            img_crop = img[:, min_val:(min_val + self.crop_size), :]\n",
    "\n",
    "            d[key] = img_crop\n",
    "        return d\n",
    "\n",
    "class CropImages(MapTransform):\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, source_key : str, crop_size, crop_allowance=10, allow_missing_keys: bool = False) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.source_key = source_key\n",
    "        self.crop_size = crop_size\n",
    "        self.crop_allowance = crop_allowance\n",
    "\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "\n",
    "        d = dict(data)\n",
    "        for ki, key in enumerate(self.keys):\n",
    "            preliminary = data[self.source_key]\n",
    "            min_val = max(preliminary.min() - self.crop_allowance, 0)\n",
    "            img = data[key]\n",
    "            img_crop = img[:, min_val:(min_val + self.crop_size), :]\n",
    "\n",
    "            d[key] = img_crop\n",
    "        return d\n",
    "\n",
    "class CropValImages(MapTransform):\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, source_key : str, crop_size, crop_allowance=10, allow_missing_keys: bool = False) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.source_key = source_key\n",
    "        self.crop_size = crop_size\n",
    "        self.crop_allowance = crop_allowance\n",
    "        self.positions = [0, 1, 3, 5, 7]\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "\n",
    "        d = dict(data)\n",
    "        for ki, key in enumerate(self.keys):\n",
    "            crop_id = data[self.source_key]\n",
    "            img = data[key]\n",
    "            img_crop = img[:, :, (self.positions[crop_id]*100):(self.positions[crop_id]*100 + self.crop_size)]\n",
    "\n",
    "            d[key] = img_crop\n",
    "        return d\n",
    "\n",
    "class BilateralFilter(MapTransform):\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, allow_missing_keys: bool = False) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "\n",
    "\n",
    "    def __call__(self, data):\n",
    "        d = dict(data)\n",
    "        for ki, key in enumerate(self.keys):\n",
    "            img = data[key]\n",
    "            #img_filter = np.expand_dims(cv2.bilateralFilter(img[0], 10, 50, 50), 0)\n",
    "            img_filter = img\n",
    "            d[key] = img_filter\n",
    "        return d\n",
    "\n",
    "class ConvertToMultiChannelMasks(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels of ong image into 0,1,2,3\n",
    "    0 - background\n",
    "    1 - RNFL\n",
    "    2 - GCIPL\n",
    "    3 - Choroid\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, keys: KeysCollection, target_keys: List[str], allow_missing_keys: bool = False) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.target_keys = target_keys\n",
    "\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "\n",
    "        d = dict(data)\n",
    "        for ki, key in enumerate(self.keys):\n",
    "\n",
    "            mask = data[key]\n",
    "            h, w= mask.shape\n",
    "\n",
    "            mask_new = np.zeros((len(labels_mapping), h, w),dtype=np.uint8)\n",
    "                      \n",
    "\n",
    "            for i, (k, v) in enumerate(labels_mapping.items()):\n",
    "                mask_new[i][mask==k] = 1\n",
    "\n",
    "            d[self.target_keys[ki]] = mask_new[1:]\n",
    "        return d\n",
    "\n",
    "class GetMaskPositions(MapTransform):\n",
    "    def __init__(self, keys: KeysCollection, target_keys: List[str], allow_missing_keys: bool = False) -> None:\n",
    "        super().__init__(keys, allow_missing_keys)\n",
    "        self.target_keys = target_keys\n",
    "\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "\n",
    "        d = dict(data)\n",
    "        for ki, key in enumerate(self.keys):\n",
    "\n",
    "            mask = data[key]\n",
    "            num, h, w = mask.shape\n",
    "\n",
    "            mask_positions = np.zeros((num * 2, w),dtype=np.float32)\n",
    "                      \n",
    "\n",
    "            for i in range(num):\n",
    "                mask_positions[i*2] = np.argmax(mask[i], axis=0)\n",
    "                mask_positions[i*2 + 1] = h - np.argmax(np.flip(mask[i], axis=0), axis=0)\n",
    "\n",
    "            # The first and the second masks share a common border\n",
    "            removal_mask = np.ones(len(mask_positions), dtype=bool)\n",
    "            removal_mask[1] = False\n",
    "            mask_positions = mask_positions[removal_mask]\n",
    "            mask_positions = np.expand_dims(mask_positions, 1)\n",
    "            d[self.target_keys[ki]] = mask_positions\n",
    "            d[\"invalid_masks\"] = np.ones_like(mask_positions)\n",
    "        return d\n",
    "\n",
    "\n",
    "class ConvertToMultiChannelGOALS(MapTransform):\n",
    "    \"\"\"\n",
    "    Convert labels of ong image into 0,1,2,3\n",
    "    0 - background\n",
    "    1 - RNFL\n",
    "    2 - GCIPL\n",
    "    3 - Choroid\n",
    "    \"\"\"\n",
    "\n",
    "    def __call__(self, data):\n",
    "\n",
    "\n",
    "        d = dict(data)\n",
    "        for key in self.keys:\n",
    "\n",
    "            mask = data[key]\n",
    "\n",
    "            mask_new = np.zeros_like(mask,dtype=np.uint8)\n",
    "\n",
    "            for k,v in labels_mapping.items():\n",
    "                mask_new[mask==k] = v\n",
    "\n",
    "            d[key] = mask_new\n",
    "        return d\n",
    "\n",
    "\n",
    "transforms = Compose([\n",
    "    LoadImaged(keys=['image','segmentation']),\n",
    "    Lambdad(keys=['image','segmentation'], func = lambda x: x.transpose()[0:1]),\n",
    "    #Lambdad(keys=['image','segmentation'], func = lambda x: np.expand_dims(x, 0)),\n",
    "    #AddChanneld(keys=['image','segmentation']),\n",
    "    RandZoomd(keys=[\"image\", \"segmentation\"], mode=[\"area\", \"nearest-exact\"], prob=0.3, min_zoom=1.3, max_zoom=1.3),\n",
    "    Resized(keys=[\"image\", \"segmentation\"], mode=[\"area\", \"nearest-exact\"], spatial_size=[-1, 400]), # We first only resize horizontally, for the correct image width\n",
    "    RandFlipd(keys=[\"image\", \"segmentation\"], spatial_axis=1, prob=0.3),\n",
    "    RandHistogramShiftd(keys=[\"image\"], prob=0.3),\n",
    "    RandAffined(keys=[\"image\", \"segmentation\"], prob=0.3, shear_range=[(-0.7, 0.7), (0.0, 0.0)], translate_range=[(-300, 100), (0, 0)], mode=[\"bilinear\", \"nearest\"], padding_mode=\"zeros\"),\n",
    "    Lambdad(keys=['image','segmentation'], func = lambda x: x[0, ...]),\n",
    "    ConvertToMultiChannelMasks(keys=['segmentation'], target_keys=[\"masks\"]),\n",
    "    GetMaskPositions(keys=['masks'], target_keys=[\"mask_positions\"]), #We get the layer position, but on the original height\n",
    "    #AddChanneld(keys=['image','segmentation']),\n",
    "    Resized(keys=[\"image\", \"segmentation\", \"masks\"], mode=[\"area\", \"nearest-exact\", \"nearest-exact\"], spatial_size=[400, 400]),\n",
    "    Lambdad(keys=['mask_positions'], func = lambda x: x * 400 / 800), #We scale down the positions to have more accurate positions\n",
    "    #Lambdad(keys=['image'], func = lambda x: np.clip((x - x.mean()) / x.std(), -1, 1)),\n",
    "    Lambdad(keys=['image'], func = lambda x: 2*(x - x.min()) / (x.max() - x.min()) - 1 ),\n",
    "    LayerPositionToProbabilityMap([\"mask_positions\"], target_size=(400,400), target_keys=[\"mask_probability_map\"])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = OCTDataset(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 26\u001b[0m, in \u001b[0;36mOCTDataset.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m---> 26\u001b[0m     source_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msource_domain_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     27\u001b[0m     target_img \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_domain_dict[index]\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform:\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# Apply transformations dynamically during training\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "optima",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
